import streamlit as st
import pandas as pd
from datetime import datetime
import json
import time

# é¦–å…ˆéœ€è¦å®‰è£ Streamlit
# !pip install streamlit plotly pandas

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="Prompt ç”Ÿæˆå™¨ RAG ç³»çµ±",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šç¾© CSS æ¨£å¼
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        background: linear-gradient(90deg, #1f77b4, #ff7f0e);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-weight: bold;
    }
    
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin: 0.5rem 0;
    }
    
    .category-card {
        background: #f8f9fa;
        border: 1px solid #e9ecef;
        border-radius: 8px;
        padding: 1rem;
        margin: 0.5rem 0;
        border-left: 4px solid #007bff;
    }
    
    .prompt-preview {
        background: #f1f3f4;
        border-radius: 8px;
        padding: 1rem;
        margin: 0.5rem 0;
        border-left: 3px solid #28a745;
        font-family: 'Courier New', monospace;
        font-size: 0.9rem;
    }
    
    .context-box {
        background: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
    }
    
    .success-box {
        background: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
        color: #155724;
    }
    
    .warning-box {
        background: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
        color: #856404;
    }
    
    .sidebar-metric {
        background: #e3f2fd;
        padding: 0.5rem;
        border-radius: 5px;
        margin: 0.2rem 0;
    }
</style>
""", unsafe_allow_html=True)

class StreamlitRAGInterface:
    """
    Streamlit å‰ç«¯ç•Œé¢é¡
    """
    
    def __init__(self):
        self.rag_system = None
        self.system_stats = None
        self.initialize_session_state()
    
    def initialize_session_state(self):
        """åˆå§‹åŒ– session state"""
        if 'system_loaded' not in st.session_state:
            st.session_state.system_loaded = False
        if 'search_history' not in st.session_state:
            st.session_state.search_history = []
        if 'current_results' not in st.session_state:
            st.session_state.current_results = None
        if 'selected_category' not in st.session_state:
            st.session_state.selected_category = None
    
    def load_system(self):
        """è¼‰å…¥ RAG ç³»çµ±"""
        try:
            # é€™è£¡æ‡‰è©²è¼‰å…¥ä¹‹å‰å»ºç«‹çš„ç³»çµ±
            # å‡è¨­ç³»çµ±å·²ç¶“åœ¨å…¨å±€è®Šæ•¸ä¸­
            if 'rag_system' in globals() and 'system_stats' in globals():
                self.rag_system = globals()['rag_system']
                self.system_stats = globals()['system_stats']
                st.session_state.system_loaded = True
                return True
            else:
                return False
        except Exception as e:
            st.error(f"è¼‰å…¥ç³»çµ±å¤±æ•—ï¼š{str(e)}")
            return False
    
    def render_header(self):
        """æ¸²æŸ“é é¢æ¨™é¡Œ"""
        st.markdown('<h1 class="main-header">ğŸš€ Prompt ç”Ÿæˆå™¨ RAG ç³»çµ±</h1>', unsafe_allow_html=True)
        
        # å‰¯æ¨™é¡Œ
        st.markdown("""
        <div style="text-align: center; color: #666; margin-bottom: 2rem;">
            <h3>æ™ºèƒ½ Prompt æª¢ç´¢èˆ‡ç”Ÿæˆå¹³å°</h3>
            <p>åŸºæ–¼ LlamaIndex å’Œ Chroma çš„å…ˆé€² RAG æ¶æ§‹</p>
        </div>
        """, unsafe_allow_html=True)
    
    def render_sidebar(self):
        """æ¸²æŸ“å´é‚Šæ¬„"""
        with st.sidebar:
            st.markdown("## ğŸ›ï¸ ç³»çµ±æ§åˆ¶å°")
            
            # ç³»çµ±ç‹€æ…‹
            if st.session_state.system_loaded:
                st.markdown('<div class="sidebar-metric">âœ… ç³»çµ±å·²è¼‰å…¥</div>', unsafe_allow_html=True)
            else:
                st.markdown('<div class="sidebar-metric">âŒ ç³»çµ±æœªè¼‰å…¥</div>', unsafe_allow_html=True)
                if st.button("ğŸ”„ è¼‰å…¥ç³»çµ±", type="primary"):
                    with st.spinner("è¼‰å…¥ç³»çµ±ä¸­..."):
                        if self.load_system():
                            st.success("ç³»çµ±è¼‰å…¥æˆåŠŸï¼")
                            time.sleep(1) # è®“ä½¿ç”¨è€…çœ‹åˆ°æˆåŠŸè¨Šæ¯
                            st.rerun()
                        else:
                            st.error("ç³»çµ±è¼‰å…¥å¤±æ•—ï¼Œè«‹ç¢ºèªç³»çµ±å·²æ­£ç¢ºåˆå§‹åŒ–")
            
            if st.session_state.system_loaded and self.system_stats:
                st.markdown("## ğŸ“Š ç³»çµ±çµ±è¨ˆ")
                
                # æ•¸æ“šçµ±è¨ˆ
                stats = self.system_stats.get("collections", {})
                total_docs = sum(stats.values()) if stats else 0
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("ç¸½æ–‡æª”æ•¸", f"{total_docs:,}")
                with col2:
                    st.metric("Collections", len(stats))
                
                # Collection è©³æƒ…
                if stats:
                    st.markdown("### Collection åˆ†ä½ˆ")
                    for name, count in stats.items():
                        percentage = (count / total_docs * 100) if total_docs > 0 else 0
                        st.markdown(f"ğŸ“ **{name}**: {count:,} ({percentage:.1f}%)")
                
                # æœå°‹æ­·å²
                if st.session_state.search_history:
                    st.markdown("## ğŸ•’ æœå°‹æ­·å²")
                    for i, search in enumerate(reversed(st.session_state.search_history[-5:]), 1):
                        with st.expander(f"æœå°‹ {i}: {search['query'][:20]}..."):
                            st.write(f"**æŸ¥è©¢**: {search['query']}")
                            st.write(f"**æ™‚é–“**: {search['timestamp']}")
                            st.write(f"**å ´æ™¯**: {search['scenario']}")
                            if search.get('context'):
                                st.write(f"**æœ‰ä¸Šä¸‹æ–‡**: æ˜¯ ({len(search['context'])} å­—ç¬¦)")
                            else:
                                st.write(f"**æœ‰ä¸Šä¸‹æ–‡**: å¦")
                
                # æ¸…é™¤æ­·å²
                if st.button("ğŸ—‘ï¸ æ¸…é™¤æœå°‹æ­·å²"):
                    st.session_state.search_history = []
                    st.success("æœå°‹æ­·å²å·²æ¸…é™¤")
                    st.rerun()
    
    def render_main_interface(self):
        """æ¸²æŸ“ä¸»ç•Œé¢"""
        if not st.session_state.system_loaded:
            st.markdown("""
            <div class="warning-box">
                <h3>âš ï¸ ç³»çµ±æœªè¼‰å…¥</h3>
                <p>è«‹å…ˆåœ¨å·¦å´é¢æ¿é»æ“Šã€Œè¼‰å…¥ç³»çµ±ã€æŒ‰éˆ•å¾Œå†ä½¿ç”¨ã€‚</p>
            </div>
            """, unsafe_allow_html=True)
            return
        
        # ä¸»è¦åŠŸèƒ½æ¨™ç±¤é 
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ” æ™ºèƒ½æœå°‹", "ğŸ¯ éæ¿¾æª¢ç´¢", "ğŸ“Š ç³»çµ±åˆ†æ", "ğŸ’¡ ä½¿ç”¨èªªæ˜"])
        
        with tab1:
            self.render_smart_search()
        
        with tab2:
            self.render_filtered_search()
        
        with tab3:
            self.render_system_analysis()
        
        with tab4:
            self.render_help_guide()
    
    def render_smart_search(self):
        """æ¸²æŸ“æ™ºèƒ½æœå°‹ç•Œé¢"""
        st.markdown("## ğŸ” æ™ºèƒ½ Prompt æœå°‹")
        
        # æœå°‹è¡¨å–®
        with st.form("search_form"):
            col1, col2 = st.columns([3, 1])
            
            with col1:
                user_query = st.text_input(
                    "è«‹è¼¸å…¥æ‚¨çš„éœ€æ±‚",
                    placeholder="ä¾‹å¦‚ï¼šå¹«æˆ‘å¯«ä¸€å°è¡ŒéŠ·éƒµä»¶ã€ç”Ÿæˆ Python æ’åºç®—æ³•ã€çµ¦æˆ‘ä¸€äº›é—œæ–¼å¤ªç©ºæ¢ç´¢çš„å‰µæ„å¯«ä½œé»å­...",
                    help="è¼¸å…¥æ‚¨æƒ³è¦çš„ prompt é¡å‹æˆ–å…·é«”éœ€æ±‚"
                )
            
            with col2:
                search_mode = st.selectbox(
                    "æœå°‹æ¨¡å¼",
                    ["è‡ªå‹•æª¢æ¸¬", "ç„¡ä¸Šä¸‹æ–‡", "æœ‰ä¸Šä¸‹æ–‡"],
                    help="é¸æ“‡æœå°‹æ¨¡å¼ã€‚'è‡ªå‹•æª¢æ¸¬' æœƒæ ¹æ“šæ˜¯å¦æä¾›ä¸Šä¸‹æ–‡ä¾†æ±ºå®šæ¨¡å¼ã€‚"
                )
            
            # ä¸Šä¸‹æ–‡è¼¸å…¥å€åŸŸ
            context_content = st.text_area(
                "ä¸Šä¸‹æ–‡å…§å®¹ (å¯é¸)",
                placeholder="å¦‚æœæ‚¨æœ‰å…·é«”çš„å…§å®¹éœ€è¦è™•ç†ï¼Œè«‹è²¼åˆ°é€™è£¡...\nä¾‹å¦‚ï¼šè¦å›è¦†çš„éƒµä»¶ã€éœ€è¦è§£é‡‹çš„ç¨‹å¼ç¢¼ã€è¦æ‘˜è¦çš„æ–‡ç« ç­‰",
                height=120,
                help="æä¾›ä¸Šä¸‹æ–‡å¯ä»¥ç²å¾—æ›´ç²¾ç¢ºçš„å®¢è£½åŒ– prompt"
            )
            
            # æœå°‹æŒ‰éˆ•
            search_submitted = st.form_submit_button("ğŸš€ é–‹å§‹æœå°‹", type="primary")
        
        # è™•ç†æœå°‹
        if search_submitted and user_query:
            self.process_search(user_query, context_content, search_mode)
        
        # é¡¯ç¤ºæœå°‹çµæœ
        if st.session_state.current_results:
            self.display_search_results(st.session_state.current_results)
    
    def process_search(self, user_query, context_content, search_mode):
        """è™•ç†æœå°‹è«‹æ±‚"""
        with st.spinner("ğŸ” æœå°‹ä¸­ï¼Œè«‹ç¨å€™..."):
            try:
                # æº–å‚™ä¸Šä¸‹æ–‡
                context = context_content.strip() if context_content else None
                
                # è‡ªå‹•æª¢æ¸¬æ¨¡å¼é‚è¼¯
                if search_mode == "è‡ªå‹•æª¢æ¸¬":
                    final_context = context
                elif search_mode == "ç„¡ä¸Šä¸‹æ–‡":
                    final_context = None
                elif search_mode == "æœ‰ä¸Šä¸‹æ–‡":
                    if not context:
                        st.warning("æ‚¨é¸æ“‡äº†'æœ‰ä¸Šä¸‹æ–‡'æ¨¡å¼ï¼Œä½†æœªæä¾›ä»»ä½•ä¸Šä¸‹æ–‡å…§å®¹ã€‚è«‹åœ¨æ–‡æœ¬æ¡†ä¸­è¼¸å…¥å…§å®¹ã€‚")
                        return
                    final_context = context
                
                # æ¨¡æ“¬APIèª¿ç”¨å»¶é²
                time.sleep(1.5)
                
                # èª¿ç”¨ RAG ç³»çµ±
                result = self.rag_system.query(user_query, final_context)
                
                if "error" in result:
                    st.error(f"æœå°‹å¤±æ•—ï¼š{result['error']}")
                    return
                
                # ä¿å­˜çµæœ
                st.session_state.current_results = result
                
                # æ·»åŠ åˆ°æœå°‹æ­·å²
                st.session_state.search_history.append({
                    "query": user_query,
                    "context": final_context,
                    "scenario": result.get("scenario"),
                    "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                })
                
                st.success("ğŸ‰ æœå°‹å®Œæˆï¼")
                
            except Exception as e:
                st.error(f"æœå°‹éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
    
    def display_search_results(self, results):
        """é¡¯ç¤ºæœå°‹çµæœ"""
        st.markdown("---")
        st.markdown("## ğŸ“‹ æœå°‹çµæœ")
        
        scenario = results.get("scenario")
        formatted_response = results.get("formatted_response", {})
        
        # çµæœæ‘˜è¦
        col1, col2, col3 = st.columns(3)
        with col1:
            st.markdown(f"""
            <div class="metric-card">
                <h4>ğŸ¯ æª¢æ¸¬å ´æ™¯</h4>
                <p>{scenario}</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            mode = results.get("response_mode", "unknown")
            st.markdown(f"""
            <div class="metric-card">
                <h4>âš™ï¸ è™•ç†æ¨¡å¼</h4>
                <p>{mode}</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            if scenario == "no_context":
                count = len(formatted_response.get("categories", {}))
                st.markdown(f"""
                <div class="metric-card">
                    <h4>ğŸ“Š æ‰¾åˆ°åˆ†é¡</h4>
                    <p>{count} å€‹</p>
                </div>
                """, unsafe_allow_html=True)
            else:
                confidence = formatted_response.get("confidence", "medium")
                st.markdown(f"""
                <div class="metric-card">
                    <h4>ğŸ¯ ä¿¡å¿ƒåº¦</h4>
                    <p>{confidence.capitalize()}</p>
                </div>
                """, unsafe_allow_html=True)
        
        # æ ¹æ“šå ´æ™¯é¡¯ç¤ºä¸åŒå…§å®¹
        if scenario == "no_context":
            self.display_category_results(formatted_response)
        else:
            self.display_context_results(formatted_response)
    
    def display_category_results(self, formatted_response):
        """é¡¯ç¤ºåˆ†é¡çµæœ"""
        categories = formatted_response.get("categories", {})
        filter_suggestions = formatted_response.get("filter_suggestions", [])
        
        if not categories:
            st.warning("æœªæ‰¾åˆ°ç›¸é—œçš„ promptï¼Œè«‹å˜—è©¦å…¶ä»–é—œéµè©")
            return
        
        st.markdown("### ğŸ·ï¸ æŒ‰åˆ†é¡ç€è¦½ Prompt")
        
        # åˆ†é¡é¸æ“‡å™¨
        category_names = list(categories.keys())
        selected_category = st.selectbox(
            "é¸æ“‡åˆ†é¡",
            category_names,
            help="é¸æ“‡ä¸€å€‹åˆ†é¡æŸ¥çœ‹ç›¸é—œçš„ prompt"
        )
        
        if selected_category and selected_category in categories:
            category_info = categories[selected_category]
            
            st.markdown(f"""
            <div class="category-card">
                <h4>{selected_category}</h4>
                <p><strong>é¡å‹</strong>: {category_info['prompt_type']}</p>
                <p><strong>æ•¸é‡</strong>: {category_info['count']} å€‹ç›¸é—œ prompt</p>
            </div>
            """, unsafe_allow_html=True)
            
            # é¡¯ç¤º prompt
            prompts = category_info.get("prompts", [])
            for i, prompt in enumerate(prompts, 1):
                unique_key = f"copy_{selected_category}_{i}"
                with st.expander(f"Prompt {i} (ç›¸ä¼¼åº¦: {prompt['score']:.3f}) - {prompt['complexity'].capitalize()}"):
                    st.markdown(f"""
                    <div class="prompt-preview">
                        {prompt['text'].replace('<', '&lt;').replace('>', '&gt;')[:500]}{'...' if len(prompt['text']) > 500 else ''}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.write(f"**è¤‡é›œåº¦**: {prompt['complexity']}")
                    with col2:
                        st.write(f"**ç›¸ä¼¼åº¦**: {prompt['score']:.3f}")
                    with col3:
                        if st.button(f"ğŸ“‹ è¤‡è£½ Prompt {i}", key=unique_key):
                            st.code(prompt['text'], language="text")
                            st.success("Prompt å·²è¤‡è£½åˆ°å‰ªè²¼ç°¿ï¼") # Streamlit doesn't actually copy, but this provides good UX.
        
        # éæ¿¾å»ºè­°
        if filter_suggestions:
            st.markdown("### ğŸ’¡ å»ºè­°çš„éæ¿¾é¸é …")
            st.write("ä»¥ä¸‹æ˜¯åŸºæ–¼æœå°‹çµæœçš„éæ¿¾å»ºè­°ï¼Œå¯ä»¥å¹«åŠ©æ‚¨åœ¨ã€Œéæ¿¾æª¢ç´¢ã€åˆ†é ä¸­æ‰¾åˆ°æ›´ç²¾ç¢ºçš„ promptï¼š")
            
            for suggestion in filter_suggestions:
                with st.expander(f"{suggestion['filter_name']} ({suggestion['count']} å€‹çµæœ)"):
                    st.write(f"**é¡å‹**: {suggestion['prompt_type']}")
                    st.write(f"**è¤‡é›œåº¦åˆ†ä½ˆ**: {suggestion.get('complexity_distribution', {})}")
                    if suggestion.get('sample_techniques'):
                        st.write(f"**ä¸»è¦æŠ€å·§**: {', '.join(suggestion['sample_techniques'][:3])}")
    
    def display_context_results(self, formatted_response):
        """é¡¯ç¤ºä¸Šä¸‹æ–‡çµæœ"""
        customized_prompt = formatted_response.get("customized_prompt", "")
        context_analysis = formatted_response.get("context_analysis", {})
        source_prompts = formatted_response.get("source_prompts", [])
        expected_outputs = formatted_response.get("expected_outputs", [])
        
        # å®¢è£½åŒ– Prompt
        if customized_prompt:
            st.markdown("### ğŸ¯ å®¢è£½åŒ– Prompt")
            st.markdown(f"""
            <div class="success-box">
                <h4>âœ¨ ç‚ºæ‚¨é‡èº«æ‰“é€ çš„ Prompt</h4>
                <div class="prompt-preview">
                    {customized_prompt.replace('<', '&lt;').replace('>', '&gt;')}
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            # è¤‡è£½æŒ‰éˆ•
            if st.button("ğŸ“‹ è¤‡è£½å®¢è£½åŒ– Prompt", type="primary"):
                st.code(customized_prompt, language="text")
                st.success("å®¢è£½åŒ– Prompt å·²è¤‡è£½åˆ°å‰ªè²¼ç°¿ï¼")
        
        with st.expander("ğŸ” æŸ¥çœ‹ç”Ÿæˆç´°ç¯€ (ä¸Šä¸‹æ–‡åˆ†æèˆ‡æº Prompt)"):
            # ä¸Šä¸‹æ–‡åˆ†æ
            if context_analysis:
                st.markdown("### ğŸ“„ ä¸Šä¸‹æ–‡åˆ†æ")
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"**å…§å®¹é¡å‹**: {context_analysis.get('content_type', 'general')}")
                with col2:
                    st.write(f"**å…§å®¹é•·åº¦**: {context_analysis.get('length', 0)} å­—ç¬¦")
                
                if context_analysis.get('summary'):
                    st.write(f"**åˆ†ææ‘˜è¦**: {context_analysis['summary']}")
            
            # æº Prompt ä¿¡æ¯
            if source_prompts:
                st.markdown("### ğŸ“š åƒè€ƒçš„æº Prompt")
                st.write(f"æœ¬æ¬¡å®¢è£½åŒ–åŸºæ–¼ {len(source_prompts)} å€‹é«˜å“è³ªçš„æº promptï¼š")
                
                for i, source in enumerate(source_prompts, 1):
                    st.markdown(f"**æº Prompt {i} (ç›¸ä¼¼åº¦: {source['score']:.3f})**")
                    st.write(f"**é¡å‹**: {source['prompt_type']}, **è¤‡é›œåº¦**: {source['complexity']}, **æŠ€å·§**: {source['techniques']}")
                    st.markdown(f"""
                    <div class="prompt-preview" style="background: #e9ecef;">
                        {source['original_text'].replace('<', '&lt;').replace('>', '&gt;')[:300]}...
                    </div>
                    """, unsafe_allow_html=True)
        
        # æœŸæœ›è¼¸å‡º
        if expected_outputs:
            st.markdown("### ğŸ’¡ æœŸæœ›è¼¸å‡ºç¯„ä¾‹")
            for i, output in enumerate(expected_outputs, 1):
                with st.expander(f"è¼¸å‡ºç¯„ä¾‹ {i}"):
                    st.markdown(f"""
                    <div class="context-box">
                        {output.replace('<', '&lt;').replace('>', '&gt;')[:400]}{'...' if len(output) > 400 else ''}
                    </div>
                    """, unsafe_allow_html=True)
    
    def render_filtered_search(self):
        """æ¸²æŸ“éæ¿¾æª¢ç´¢ç•Œé¢"""
        st.markdown("## ğŸ¯ é€²éšéæ¿¾æª¢ç´¢")
        st.write("ä½¿ç”¨é€²éšéæ¿¾åŠŸèƒ½ï¼Œç²¾ç¢ºæ‰¾åˆ°ç¬¦åˆç‰¹å®šæ¢ä»¶çš„ promptã€‚")
        
        # éæ¿¾é¸é …
        col1, col2 = st.columns(2)
        
        with col1:
            prompt_types = [
                "CONVERSATIONAL", "CREATIVE_WRITING", "INSTRUCTIONAL", 
                "SUMMARIZATION", "ANALYSIS_CRITIQUE", "INFORMATIONAL",
                "QUESTION_ANSWERING", "PROGRAMMING_CODE_GENERATION", 
                "CODE_EXPLANATION", "COMPARISON"
            ]
            
            selected_type = st.selectbox(
                "Prompt é¡å‹",
                ["å…¨éƒ¨"] + prompt_types,
                key="filter_type",
                help="é¸æ“‡ç‰¹å®šçš„ prompt é¡å‹"
            )
        
        with col2:
            complexity_levels = ["low", "medium", "high"]
            selected_complexity = st.selectbox(
                "è¤‡é›œåº¦",
                ["å…¨éƒ¨"] + complexity_levels,
                key="filter_complexity",
                help="é¸æ“‡ prompt çš„è¤‡é›œåº¦ç­‰ç´š"
            )
        
        # æœå°‹æŸ¥è©¢
        filter_query = st.text_input(
            "æœå°‹æŸ¥è©¢ (å¯é¸)",
            placeholder="è¼¸å…¥é—œéµè©ä»¥é€²ä¸€æ­¥ç¸®å°ç¯„åœ...",
            help="åœ¨å·²éæ¿¾çš„çµæœä¸­é€²è¡Œæ–‡æœ¬æœå°‹"
        )
        
        # åŸ·è¡Œéæ¿¾æœå°‹
        if st.button("ğŸ¯ åŸ·è¡Œéæ¿¾æœå°‹", type="primary"):
            self.execute_filtered_search(filter_query, selected_type, selected_complexity)

    def execute_filtered_search(self, query, prompt_type, complexity):
        """åŸ·è¡Œéæ¿¾æœå°‹"""
        with st.spinner("ğŸ” åŸ·è¡Œéæ¿¾æœå°‹ä¸­..."):
            try:
                # æ§‹å»ºéæ¿¾æ¢ä»¶
                filters = {}
                if prompt_type != "å…¨éƒ¨":
                    filters["prompt_type"] = prompt_type
                if complexity != "å…¨éƒ¨":
                    filters["complexity"] = complexity
                
                # æ¨¡æ“¬APIèª¿ç”¨å»¶é²
                time.sleep(1)
                
                # åŸ·è¡Œéæ¿¾æœå°‹
                result = self.rag_system.apply_user_filter(query, filters)
                
                if "error" in result:
                    st.error(f"éæ¿¾æœå°‹å¤±æ•—ï¼š{result['error']}")
                    return
                
                # é¡¯ç¤ºçµæœ
                st.success(f"ğŸ‰ æ‰¾åˆ° {result['total_found']} å€‹åŒ¹é…çµæœ")
                
                if result['results']:
                    st.markdown("### ğŸ“‹ éæ¿¾çµæœ")
                    
                    for i, item in enumerate(result['results'], 1):
                        unique_key = f"filter_copy_{i}"
                        with st.expander(f"çµæœ {i} (ç›¸ä¼¼åº¦: {item['score']:.3f})"):
                            metadata = item['metadata']
                            
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.write(f"**é¡å‹**: {metadata.get('prompt_type', 'N/A')}")
                            with col2:
                                st.write(f"**è¤‡é›œåº¦**: {metadata.get('complexity', 'N/A')}")
                            with col3:
                                st.write(f"**ç›¸ä¼¼åº¦**: {item['score']:.3f}")
                            
                            st.markdown(f"""
                            <div class="prompt-preview">
                                {item['text'].replace('<', '&lt;').replace('>', '&gt;')[:400]}{'...' if len(item['text']) > 400 else ''}
                            </div>
                            """, unsafe_allow_html=True)
                            
                            if st.button(f"ğŸ“‹ è¤‡è£½çµæœ {i}", key=unique_key):
                                st.code(item['text'], language="text")
                                st.success("Prompt å·²è¤‡è£½åˆ°å‰ªè²¼ç°¿ï¼")
                else:
                    st.info("æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„çµæœï¼Œè«‹å˜—è©¦èª¿æ•´éæ¿¾æ¢ä»¶")
                    
            except Exception as e:
                st.error(f"éæ¿¾æœå°‹éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
    
    def render_system_analysis(self):
        """æ¸²æŸ“ç³»çµ±åˆ†æç•Œé¢"""
        st.markdown("## ğŸ“Š ç³»çµ±åˆ†æèˆ‡çµ±è¨ˆ")
        
        if not self.system_stats:
            st.warning("ç³»çµ±çµ±è¨ˆæ•¸æ“šä¸å¯ç”¨")
            return
        
        # ç³»çµ±æ¦‚è¦½
        st.markdown("### ğŸ¯ ç³»çµ±æ¦‚è¦½")
        
        stats = self.system_stats.get("collections", {})
        total_docs = sum(stats.values()) if stats else 0
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                label="ğŸ“š ç¸½æ–‡æª”æ•¸",
                value=f"{total_docs:,}",
                help="ç³»çµ±ä¸­æ‰€æœ‰ collection çš„æ–‡æª”ç¸½æ•¸"
            )
        
        with col2:
            st.metric(
                label="ğŸ—‚ï¸ Collections",
                value=len(stats),
                help="å‘é‡æ•¸æ“šåº«ä¸­çš„ collection æ•¸é‡"
            )
        
        with col3:
            search_count = len(st.session_state.search_history)
            st.metric(
                label="ğŸ” æœå°‹æ¬¡æ•¸",
                value=search_count,
                help="æœ¬æ¬¡æœƒè©±ä¸­çš„æœå°‹æ¬¡æ•¸"
            )
        
        with col4:
            st.metric(
                label="ğŸ”„ ç³»çµ±ç‹€æ…‹",
                value="é‹è¡Œä¸­" if st.session_state.system_loaded else "é›¢ç·š",
                help="ç•¶å‰ç³»çµ±é‹è¡Œç‹€æ…‹"
            )
        
        # Collection åˆ†ä½ˆåœ–è¡¨
        if stats:
            st.markdown("### ğŸ“Š Collection æ–‡æª”åˆ†ä½ˆ")
            
            df_stats = pd.DataFrame(list(stats.items()), columns=['Collection', 'æ–‡æª”æ•¸é‡'])

            col1, col2 = st.columns(2)

            with col1:
                # ä½¿ç”¨ Streamlit åŸç”Ÿå›¾è¡¨æ˜¾ç¤ºæ–‡æ¡£æ•°é‡å æ¯”
                st.subheader("å„ Collection æ–‡æª”æ•¸é‡ä½”æ¯”")
                st.bar_chart(df_stats.set_index('Collection')['æ–‡æª”æ•¸é‡'])
            
            with col2:
                # ä½¿ç”¨ Streamlit åŸç”Ÿå›¾è¡¨æ˜¾ç¤ºæ–‡æ¡£ç»å¯¹æ•°é‡
                st.subheader("å„ Collection æ–‡æª”çµ•å°æ•¸é‡")
                st.bar_chart(df_stats.set_index('Collection')['æ–‡æª”æ•¸é‡'])
        
        # æœå°‹æ­·å²åˆ†æ
        if st.session_state.search_history:
            st.markdown("### ğŸ“ˆ æœå°‹æ­·å²åˆ†æ")
            
            history_df = pd.DataFrame(st.session_state.search_history)
            
            # å ´æ™¯åˆ†ä½ˆ
            scenario_counts = history_df['scenario'].value_counts()
            
            col1, col2 = st.columns(2)
            
            with col1:
                if not scenario_counts.empty:
                    st.subheader("æœå°‹å ´æ™¯åˆ†ä½ˆ")
                    st.bar_chart(scenario_counts)
                else:
                    st.info("å°šç„¡è¶³å¤ çš„æœå°‹æ­·å²ä¾†åˆ†æå ´æ™¯åˆ†ä½ˆã€‚")
            
            with col2:
                # æœå°‹æ™‚é–“è¶¨å‹¢
                if not history_df.empty:
                    history_df['timestamp'] = pd.to_datetime(history_df['timestamp'])
                    hourly_counts = history_df.groupby(history_df['timestamp'].dt.hour).size().reset_index(name='count')
                    hourly_counts.set_index('timestamp', inplace=True)
                    
                    st.subheader("æ¯å°æ™‚æœå°‹æ¬¡æ•¸åˆ†ä½ˆ")
                    st.line_chart(hourly_counts)
                else:
                    st.info("å°šç„¡è¶³å¤ çš„æœå°‹æ­·å²ä¾†åˆ†ææ™‚é–“è¶¨å‹¢ã€‚")
            
            # è©³ç´°æ­·å²
            st.markdown("### ğŸ“ è©³ç´°æœå°‹æ­·å²")
            st.dataframe(
                history_df[['timestamp', 'query', 'scenario']],
                use_container_width=True
            )
            
    def render_help_guide(self):
        """æ¸²æŸ“ä½¿ç”¨èªªæ˜ç•Œé¢"""
        st.markdown("## ğŸ’¡ ä½¿ç”¨èªªæ˜èˆ‡æŒ‡å—")
        st.write("æ­¡è¿ä½¿ç”¨ Prompt ç”Ÿæˆå™¨ RAG ç³»çµ±ï¼é€™è£¡å°‡å¼•å°æ‚¨å¦‚ä½•æœ‰æ•ˆåˆ©ç”¨æœ¬å¹³å°ã€‚")

        with st.expander("ğŸš€ å¿«é€Ÿå…¥é–€", expanded=True):
            st.markdown("""
            1.  **è¼‰å…¥ç³»çµ±**: é»æ“Šå·¦å´é‚Šæ¬„çš„ `ğŸ”„ è¼‰å…¥ç³»çµ±` æŒ‰éˆ•ã€‚
            2.  **å‰å¾€æ™ºèƒ½æœå°‹**: ç³»çµ±è¼‰å…¥å¾Œï¼Œåœç•™åœ¨ `ğŸ” æ™ºèƒ½æœå°‹` æ¨™ç±¤é ã€‚
            3.  **è¼¸å…¥éœ€æ±‚**: åœ¨è¼¸å…¥æ¡†ä¸­æè¿°æ‚¨æƒ³è¦çš„ä»»å‹™ï¼Œä¾‹å¦‚ã€Œå¯«ä¸€å°é“æ­‰ä¿¡ã€æˆ–ã€Œè§£é‡‹ Python çš„ aiohttp åº«ã€ã€‚
            4.  **æä¾›ä¸Šä¸‹æ–‡ (å¯é¸)**: å¦‚æœæ‚¨çš„ä»»å‹™éœ€è¦åŸºæ–¼ç‰¹å®šå…§å®¹ï¼ˆå¦‚ä¸€å°å¾…å›è¦†çš„éƒµä»¶ï¼‰ï¼Œè«‹å°‡å…¶è²¼å…¥ã€Œä¸Šä¸‹æ–‡å…§å®¹ã€å€åŸŸã€‚
            5.  **é–‹å§‹æœå°‹**: é»æ“Š `ğŸš€ é–‹å§‹æœå°‹` æŒ‰éˆ•ã€‚
            6.  **æŸ¥çœ‹çµæœ**: ç³»çµ±æœƒè‡ªå‹•åˆ†ææ‚¨çš„éœ€æ±‚ï¼Œä¸¦æä¾›åˆ†é¡çš„ prompt å»ºè­°æˆ–ä¸€å€‹ç‚ºæ‚¨é‡èº«æ‰“é€ çš„å®¢è£½åŒ– promptã€‚
            """)

        with st.expander("ğŸ” æ™ºèƒ½æœå°‹è©³è§£"):
            st.markdown("""
            **æ™ºèƒ½æœå°‹** æ˜¯æœ¬ç³»çµ±çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œå®ƒèƒ½ç†è§£æ‚¨çš„æ„åœ–ä¸¦æä¾›æœ€ç›¸é—œçš„çµæœã€‚

            -   **ç„¡ä¸Šä¸‹æ–‡æœå°‹**:
                -   **é©ç”¨å ´æ™¯**: ç•¶æ‚¨æœ‰ä¸€å€‹é€šç”¨çš„æƒ³æ³•ï¼Œæƒ³å°‹æ‰¾é«˜å“è³ªçš„ prompt æ¨¡æ¿æ™‚ã€‚
                -   **ä¾‹å¦‚**: ã€Œå‰µæ„å¯«ä½œé»å­ã€ã€ã€Œç¸½çµæ–‡ç« çš„ promptã€ã€‚
                -   **çµæœ**: ç³»çµ±æœƒè¿”å›å¤šå€‹ç›¸é—œçš„ **åˆ†é¡**ï¼Œæ¯å€‹åˆ†é¡ä¸‹åŒ…å«å¤šå€‹ prompt ç¯„ä¾‹ï¼Œæ‚¨å¯ä»¥å¾ä¸­æŒ‘é¸ã€‚

            -   **æœ‰ä¸Šä¸‹æ–‡æœå°‹**:
                -   **é©ç”¨å ´æ™¯**: ç•¶æ‚¨éœ€è¦è™•ç†ä¸€æ®µå…·é«”æ–‡æœ¬æ™‚ã€‚
                -   **ä¾‹å¦‚**: å°‡ä¸€å°å®¢æˆ¶æŠ•è¨´éƒµä»¶è²¼å…¥ä¸Šä¸‹æ–‡ï¼Œä¸¦åœ¨éœ€æ±‚ä¸­è¼¸å…¥ã€Œå¹«æˆ‘è‰æ“¬ä¸€å°å°ˆæ¥­çš„å›è¦†ã€ã€‚
                -   **çµæœ**: ç³»çµ±æœƒåˆ†ææ‚¨çš„ä¸Šä¸‹æ–‡ï¼Œä¸¦çµåˆæ‚¨çš„éœ€æ±‚ï¼Œç”Ÿæˆä¸€å€‹ **ç¨ä¸€ç„¡äºŒçš„ã€å®¢è£½åŒ–çš„ prompt**ã€‚é€™å€‹ prompt æœƒç›´æ¥åŒ…å«æ‚¨çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ã€‚

            -   **è‡ªå‹•æª¢æ¸¬æ¨¡å¼**:
                -   é€™æ˜¯**æ¨è–¦æ¨¡å¼**ã€‚æ‚¨ç„¡éœ€é—œå¿ƒè¦é¸å“ªç¨®æ¨¡å¼ã€‚
                -   ç³»çµ±æœƒè‡ªå‹•æª¢æŸ¥ã€Œä¸Šä¸‹æ–‡å…§å®¹ã€å€åŸŸæ˜¯å¦ç‚ºç©ºã€‚å¦‚æœæœ‰å…§å®¹ï¼Œå‰‡åŸ·è¡Œã€Œæœ‰ä¸Šä¸‹æ–‡æœå°‹ã€ï¼›å¦‚æœæ²’æœ‰ï¼Œå‰‡åŸ·è¡Œã€Œç„¡ä¸Šä¸‹æ–‡æœå°‹ã€ã€‚
            """)

        with st.expander("ğŸ¯ é€²éšéæ¿¾æª¢ç´¢"):
            st.markdown("""
            ç•¶æ‚¨å°æ‰€éœ€çš„ prompt æœ‰éå¸¸å…·é«”çš„è¦æ±‚æ™‚ï¼Œå¯ä»¥ä½¿ç”¨æ­¤åŠŸèƒ½ã€‚

            -   **Prompt é¡å‹**: ç¯©é¸ç‰¹å®šç”¨é€”çš„ promptï¼Œä¾‹å¦‚ `PROGRAMMING_CODE_GENERATION` åªæœƒé¡¯ç¤ºèˆ‡ç¨‹å¼ç¢¼ç”Ÿæˆç›¸é—œçš„ promptã€‚
            -   **è¤‡é›œåº¦**: ç¯©é¸ prompt çš„è¤‡é›œç¨‹åº¦ã€‚
                -   `low`: ç°¡å–®ã€ç›´æ¥çš„æŒ‡ä»¤ã€‚
                -   `medium`: åŒ…å«å¤šå€‹æ­¥é©Ÿæˆ–ä¸€äº›é™åˆ¶æ¢ä»¶ã€‚
                -   `high`: è¤‡é›œçš„ã€å°ˆå®¶ç´šçš„ promptï¼Œå¯èƒ½åŒ…å«è©³ç´°çš„ Persona è¨­å®šã€è¼¸å‡ºæ ¼å¼è¦æ±‚ç­‰ã€‚
            -   **æœå°‹æŸ¥è©¢ (å¯é¸)**: åœ¨ä»¥ä¸Šéæ¿¾æ¢ä»¶çš„åŸºç¤ä¸Šï¼Œå†é€²è¡Œé—œéµè©æœå°‹ï¼Œé€²ä¸€æ­¥ç¸®å°ç¯„åœã€‚
            """)

        with st.expander("ğŸ“‹ è§£è®€æœå°‹çµæœ"):
            st.markdown("""
            -   **æª¢æ¸¬å ´æ™¯**: ç³»çµ±åˆ¤æ–·æ‚¨çš„æœå°‹æ˜¯ `no_context` (ç„¡ä¸Šä¸‹æ–‡) é‚„æ˜¯ `context` (æœ‰ä¸Šä¸‹æ–‡)ã€‚
            -   **è™•ç†æ¨¡å¼**: ç³»çµ±æ¡ç”¨çš„å…§éƒ¨è™•ç†ç­–ç•¥ã€‚
            -   **åˆ†é¡çµæœ (ç„¡ä¸Šä¸‹æ–‡)**:
                -   `åˆ†é¡`: æ ¹æ“šæ‚¨çš„éœ€æ±‚æ‰¾åˆ°çš„ç›¸é—œ prompt é¡åˆ¥ã€‚
                -   `Prompt é è¦½`: é»æ“Šå±•é–‹å¯çœ‹åˆ°å®Œæ•´çš„ prompt æ–‡æœ¬å’Œå…¶è¤‡é›œåº¦ã€ç›¸ä¼¼åº¦ç­‰ä¿¡æ¯ã€‚
            -   **å®¢è£½åŒ–çµæœ (æœ‰ä¸Šä¸‹æ–‡)**:
                -   `å®¢è£½åŒ– Prompt`: é€™æ˜¯ç³»çµ±ç‚ºæ‚¨é‡èº«æ‰“é€ çš„æœ€çµ‚ promptï¼Œå¯ä»¥ç›´æ¥è¤‡è£½ä½¿ç”¨ã€‚
                -   `ä¸Šä¸‹æ–‡åˆ†æ`: ç³»çµ±å°æ‚¨æä¾›çš„ä¸Šä¸‹æ–‡çš„ç†è§£ã€‚
                -   `æº Prompt`: ç³»çµ±åœ¨ç”Ÿæˆå®¢è£½åŒ– prompt æ™‚åƒè€ƒäº†å“ªäº›åŸºç¤ prompt æ¨¡æ¿ã€‚
            -   **ç›¸ä¼¼åº¦ (Score)**: ä»£è¡¨æª¢ç´¢åˆ°çš„ prompt èˆ‡æ‚¨çš„æŸ¥è©¢æœ‰å¤šç›¸é—œï¼Œåˆ†æ•¸è¶Šé«˜è¶Šç›¸é—œã€‚
            """)
            
    def run(self):
        """é‹è¡Œ Streamlit ç•Œé¢"""
        self.render_header()
        self.render_sidebar()
        self.render_main_interface()

# --- æ¨¡æ“¬å¾Œç«¯ (ç‚ºäº†æ¼”ç¤º) ---
# åœ¨å¯¦éš›æ‡‰ç”¨ä¸­ï¼Œæ‚¨æœƒå°å…¥æ‚¨çœŸå¯¦çš„ RAG ç³»çµ±é¡
class MockRAGSystem:
    def query(self, user_query, context=None):
        if context:
            # æ¨¡æ“¬æœ‰ä¸Šä¸‹æ–‡çš„å›æ‡‰
            return {
                "scenario": "context",
                "response_mode": "customization",
                "formatted_response": {
                    "customized_prompt": f"""You are a helpful assistant. Based on the following context, please respond to the user's request.

Context:
---
{context[:200]}...
---

User Request: {user_query}

Please provide a comprehensive and helpful response. Structure your output clearly.""",
                    "context_analysis": {
                        "content_type": "customer_email",
                        "length": len(context),
                        "summary": "The context appears to be a user inquiry or feedback email."
                    },
                    "source_prompts": [
                        {
                            "score": 0.92,
                            "prompt_type": "CONVERSATIONAL",
                            "complexity": "medium",
                            "techniques": "Role-playing, Context-injection",
                            "original_text": "Act as a customer support agent. Given the user's email below, draft a polite and helpful response. [Context Placeholder]"
                        }
                    ],
                    "expected_outputs": [
                        "A professionally drafted email response addressing the user's points from the context."
                    ],
                    "confidence": "high"
                }
            }
        else:
            # æ¨¡æ“¬ç„¡ä¸Šä¸‹æ–‡çš„å›æ‡‰
            return {
                "scenario": "no_context",
                "response_mode": "categorization",
                "formatted_response": {
                    "categories": {
                        "Creative Writing Prompts": {
                            "prompt_type": "CREATIVE_WRITING",
                            "count": 2,
                            "prompts": [
                                {"text": "Write a short story about a time-traveling librarian. The story should be in the first person.", "score": 0.88, "complexity": "medium"},
                                {"text": "Generate three ideas for a fantasy novel involving a forgotten magic.", "score": 0.85, "complexity": "low"}
                            ]
                        },
                        "Code Generation Prompts": {
                            "prompt_type": "PROGRAMMING_CODE_GENERATION",
                            "count": 1,
                            "prompts": [
                                {"text": "Write a Python function that takes a list of integers and returns the second largest number. Include docstrings and type hints.", "score": 0.91, "complexity": "high"}
                            ]
                        }
                    },
                    "filter_suggestions": [
                        {"filter_name": "Creative Writing", "count": 2, "prompt_type": "CREATIVE_WRITING", "complexity_distribution": {"low": 1, "medium": 1}, "sample_techniques": ["Storytelling", "Idea-generation"]}
                    ]
                }
            }

    def apply_user_filter(self, query, filters):
        # æ¨¡æ“¬éæ¿¾æœå°‹
        results = [
            {
                "text": "This is a filtered prompt for 'CONVERSATIONAL' type with 'medium' complexity.",
                "score": 0.95,
                "metadata": {"prompt_type": "CONVERSATIONAL", "complexity": "medium"}
            },
            {
                "text": "Another filtered prompt for 'CONVERSATIONAL' type, but with 'high' complexity.",
                "score": 0.91,
                "metadata": {"prompt_type": "CONVERSATIONAL", "complexity": "high"}
            }
        ]
        
        # æ ¹æ“š filters é€²è¡Œç°¡å–®éæ¿¾
        filtered_results = []
        for r in results:
            match = True
            if "prompt_type" in filters and filters["prompt_type"] != r["metadata"]["prompt_type"]:
                match = False
            if "complexity" in filters and filters["complexity"] != r["metadata"]["complexity"]:
                match = False
            if match:
                filtered_results.append(r)
        
        return {
            "total_found": len(filtered_results),
            "results": filtered_results
        }

# --- ä¸»åŸ·è¡Œå€å¡Š ---
if __name__ == "__main__":
    # å‰µå»ºæ¨¡æ“¬çš„å…¨å±€è®Šæ•¸ï¼Œä»¥ä¾› load_system æ–¹æ³•ä½¿ç”¨
    # åœ¨æ‚¨çš„çœŸå¯¦æ‡‰ç”¨ä¸­ï¼Œé€™è£¡æœƒæ˜¯æ‚¨ RAG ç³»çµ±çš„å¯¦ä¾‹åŒ–éç¨‹
    rag_system = MockRAGSystem()
    system_stats = {
        "collections": {
            "general_prompts": 1250,
            "code_prompts": 820,
            "creative_writing": 550,
            "business_communication": 680
        },
        "last_updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    
    # è¨­ç½®ç‚ºå…¨å±€è®Šæ•¸
    globals()['rag_system'] = rag_system
    globals()['system_stats'] = system_stats
    
    # å¯¦ä¾‹åŒ–ä¸¦é‹è¡Œç•Œé¢
    app = StreamlitRAGInterface()
    app.run()