#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Prompt ç”Ÿæˆå™¨ RAG ç³»çµ±
åŸºæ–¼ LlamaIndex å’Œ Chroma çš„æ™ºèƒ½ Prompt æª¢ç´¢å’Œç”Ÿæˆç³»çµ±

åŠŸèƒ½ç‰¹è‰²ï¼š
- æ™ºèƒ½æ–‡æª”åˆ‡åˆ†ç­–ç•¥
- Chroma æ··åˆæ¶æ§‹ (ä¸‰å€‹å°ˆç”¨ collection)
- é›™è»Œæª¢ç´¢ç­–ç•¥ (ç„¡ä¸Šä¸‹æ–‡ vs æœ‰ä¸Šä¸‹æ–‡)
- Response Mode è‡ªå‹•é…ç½®
- ç”¨æˆ¶å‹å¥½çš„åˆ†é¡é¡¯ç¤º

ä½œè€…ï¼šAI Assistant
å‰µå»ºæ—¥æœŸï¼š2025-06-17
"""

import os
import pandas as pd
import numpy as np
import re
import uuid
import chromadb
from chromadb.config import Settings
from chromadb.utils import embedding_functions
from typing import List, Dict, Any, Optional

# LlamaIndex å°å…¥
from llama_index.core import VectorStoreIndex, StorageContext
from llama_index.core.schema import TextNode
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI
from llama_index.core import Settings as LlamaSettings

# ç³»çµ±é…ç½®
def setup_environment(openai_api_key: str):
    """è¨­ç½®ç’°å¢ƒå’Œ LlamaIndex é…ç½®"""
    os.environ["OPENAI_API_KEY"] = openai_api_key
    LlamaSettings.llm = OpenAI(model="gpt-3.5-turbo", temperature=0.1)
    LlamaSettings.embed_model = OpenAIEmbedding(model="text-embedding-ada-002")

# [åœ¨é€™è£¡æ’å…¥æ‰€æœ‰çš„é¡å®šç¾©ï¼šSmartChunkingStrategy, ChromaMixedArchitectureFixed, HybridSearchStrategy, PromptGeneratorRAGSystem]

class PromptGeneratorRAGSystem:
    def __init__(self):
        """åˆå§‹åŒ– RAG ç³»çµ±"""
        try:
            # åˆå§‹åŒ– Chroma å®¢æˆ¶ç«¯
            self.chroma_client = chromadb.Client()
            
            # å‰µå»ºæˆ–ç²å– collection
            self.collection = self.chroma_client.get_or_create_collection(
                name="prompts",
                embedding_function=embedding_functions.OpenAIEmbeddingFunction(
                    api_key=os.getenv("OPENAI_API_KEY"),
                    model_name="text-embedding-ada-002"
                )
            )
            
            # åˆå§‹åŒ–ç³»çµ±ç‹€æ…‹
            self._initialize_system()
            
        except Exception as e:
            raise Exception(f"RAG ç³»çµ±åˆå§‹åŒ–å¤±æ•—ï¼š{str(e)}")
    
    def _initialize_system(self):
        """åˆå§‹åŒ–ç³»çµ±ç‹€æ…‹"""
        try:
            # æª¢æŸ¥æ•¸æ“šé›†æ˜¯å¦å·²è¼‰å…¥
            if self.collection.count() == 0:
                self.process_dataset()
        except Exception as e:
            raise Exception(f"ç³»çµ±ç‹€æ…‹åˆå§‹åŒ–å¤±æ•—ï¼š{str(e)}")
    
    def process_dataset(self):
        """è™•ç†ä¸¦è¼‰å…¥æ•¸æ“šé›†åˆ° Chroma"""
        try:
            # è®€å–æ•¸æ“šé›†
            df = pd.read_csv("dataset/processed_dataset.csv")
            
            # æº–å‚™æ•¸æ“š
            documents = df["prompt_text"].tolist()
            metadatas = df[["prompt_type", "complexity"]].to_dict('records')
            ids = [str(uuid.uuid4()) for _ in range(len(df))]
            
            # æ‰¹é‡æ·»åŠ åˆ° collection
            self.collection.add(
                documents=documents,
                metadatas=metadatas,
                ids=ids
            )
            
            print(f"æˆåŠŸè¼‰å…¥ {len(documents)} æ¢æ•¸æ“šåˆ° Chroma")
            return True
            
        except Exception as e:
            print(f"æ•¸æ“šé›†è™•ç†éŒ¯èª¤ï¼š{str(e)}")
            return False
    
    def apply_user_filter(self, query: str, filters: Dict[str, Any]) -> Dict[str, Any]:
        """åŸ·è¡Œéæ¿¾æœç´¢
        
        Args:
            query: ç”¨æˆ¶æœç´¢æŸ¥è©¢
            filters: éæ¿¾æ¢ä»¶ï¼ŒåŒ…å« prompt_type å’Œ complexity
            
        Returns:
            æœç´¢çµæœå­—å…¸
        """
        try:
            # æ§‹å»ºæŸ¥è©¢æ¢ä»¶
            where_clause = {}
            if "prompt_type" in filters and filters["prompt_type"]:
                where_clause["prompt_type"] = filters["prompt_type"]
            if "complexity" in filters and filters["complexity"]:
                where_clause["complexity"] = filters["complexity"]
            
            # åŸ·è¡Œå‘é‡æœç´¢
            results = self.collection.query(
                query_texts=[query],
                n_results=10,
                where=where_clause if where_clause else None
            )
            
            # æ ¼å¼åŒ–çµæœ
            formatted_results = []
            if results['ids'] and len(results['ids'][0]) > 0:
                for i in range(len(results['ids'][0])):
                    formatted_results.append({
                        "text": results['documents'][0][i],
                        "score": float(results['distances'][0][i]),
                        "metadata": {
                            "prompt_type": results['metadatas'][0][i].get('prompt_type'),
                            "complexity": results['metadatas'][0][i].get('complexity')
                        }
                    })
            
            return {
                "total_found": len(formatted_results),
                "results": formatted_results
            }
            
        except Exception as e:
            print(f"æœç´¢éŒ¯èª¤ï¼š{str(e)}")
            return {
                "total_found": 0,
                "results": [],
                "error": str(e)
            }
    
    def query(self, user_query: str, context: Optional[str] = None) -> Dict[str, Any]:
        """è™•ç†ç”¨æˆ¶æŸ¥è©¢
        
        Args:
            user_query: ç”¨æˆ¶æŸ¥è©¢
            context: å¯é¸çš„ä¸Šä¸‹æ–‡å…§å®¹
            
        Returns:
            æŸ¥è©¢çµæœå­—å…¸
        """
        try:
            # æ ¹æ“šæ˜¯å¦æœ‰ä¸Šä¸‹æ–‡é¸æ“‡ä¸åŒçš„è™•ç†é‚è¼¯
            if context:
                return self._handle_context_query(user_query, context)
            else:
                return self._handle_no_context_query(user_query)
        except Exception as e:
            return {"error": str(e)}
    
    def _handle_context_query(self, query: str, context: str) -> Dict[str, Any]:
        """è™•ç†æœ‰ä¸Šä¸‹æ–‡çš„æŸ¥è©¢"""
        try:
            # ä½¿ç”¨ä¸Šä¸‹æ–‡å’ŒæŸ¥è©¢é€²è¡Œæœç´¢
            results = self.collection.query(
                query_texts=[f"{query} {context}"],
                n_results=3
            )
            
            if not results['ids'] or len(results['ids'][0]) == 0:
                return {
                    "scenario": "context",
                    "response_mode": "customization",
                    "error": "æœªæ‰¾åˆ°ç›¸é—œçµæœ"
                }
            
            # è¿”å›å®¢è£½åŒ–çµæœ
            return {
                "scenario": "context",
                "response_mode": "customization",
                "formatted_response": {
                    "customized_prompt": self._generate_custom_prompt(query, context, results),
                    "context_analysis": self._analyze_context(context),
                    "source_prompts": [
                        {
                            "score": float(results['distances'][0][i]),
                            "prompt_type": results['metadatas'][0][i].get('prompt_type'),
                            "complexity": results['metadatas'][0][i].get('complexity'),
                            "original_text": results['documents'][0][i]
                        }
                        for i in range(len(results['ids'][0]))
                    ]
                }
            }
        except Exception as e:
            return {
                "scenario": "context",
                "response_mode": "customization",
                "error": str(e)
            }
    
    def _handle_no_context_query(self, query: str) -> Dict[str, Any]:
        """è™•ç†ç„¡ä¸Šä¸‹æ–‡çš„æŸ¥è©¢"""
        try:
            # åŸ·è¡ŒåŸºæœ¬æœç´¢
            results = self.collection.query(
                query_texts=[query],
                n_results=5
            )
            
            if not results['ids'] or len(results['ids'][0]) == 0:
                return {
                    "scenario": "no_context",
                    "response_mode": "categorization",
                    "error": "æœªæ‰¾åˆ°ç›¸é—œçµæœ"
                }
            
            # å°çµæœé€²è¡Œåˆ†é¡
            categories = self._categorize_results(results)
            
            return {
                "scenario": "no_context",
                "response_mode": "categorization",
                "formatted_response": {
                    "categories": categories,
                    "filter_suggestions": self._generate_filter_suggestions(results)
                }
            }
        except Exception as e:
            return {
                "scenario": "no_context",
                "response_mode": "categorization",
                "error": str(e)
            }
    
    def _generate_custom_prompt(self, query: str, context: str, results: Dict) -> str:
        """ç”Ÿæˆå®¢è£½åŒ– prompt"""
        # ä½¿ç”¨æœ€ç›¸é—œçš„ prompt ä½œç‚ºæ¨¡æ¿
        template = results['documents'][0][0]
        return template.replace("[Context Placeholder]", context)
    
    def _analyze_context(self, context: str) -> Dict[str, Any]:
        """åˆ†æä¸Šä¸‹æ–‡å…§å®¹"""
        return {
            "content_type": "user_input",
            "length": len(context),
            "summary": context[:200] + "..." if len(context) > 200 else context
        }
    
    def _categorize_results(self, results: Dict) -> Dict[str, Any]:
        """å°‡æœç´¢çµæœåˆ†é¡"""
        categories = {}
        
        for i in range(len(results['ids'][0])):
            prompt_type = results['metadatas'][0][i].get('prompt_type', 'Other')
            
            if prompt_type not in categories:
                categories[prompt_type] = {
                    "prompt_type": prompt_type,
                    "count": 0,
                    "prompts": []
                }
            
            categories[prompt_type]["count"] += 1
            categories[prompt_type]["prompts"].append({
                "text": results['documents'][0][i],
                "score": float(results['distances'][0][i]),
                "complexity": results['metadatas'][0][i].get('complexity', 'medium')
            })
        
        return categories
    
    def _generate_filter_suggestions(self, results: Dict) -> List[Dict[str, Any]]:
        """ç”Ÿæˆéæ¿¾å»ºè­°"""
        suggestions = []
        prompt_types = {}
        complexities = {}
        
        for i in range(len(results['ids'][0])):
            prompt_type = results['metadatas'][0][i].get('prompt_type')
            complexity = results['metadatas'][0][i].get('complexity')
            
            if prompt_type:
                prompt_types[prompt_type] = prompt_types.get(prompt_type, 0) + 1
            if complexity:
                complexities[complexity] = complexities.get(complexity, 0) + 1
        
        for prompt_type, count in prompt_types.items():
            suggestions.append({
                "filter_name": prompt_type,
                "count": count,
                "prompt_type": prompt_type,
                "complexity_distribution": complexities
            })
        
        return suggestions

def main():
    """ä¸»å‡½æ•¸ - ç³»çµ±åˆå§‹åŒ–å’Œæ¸¬è©¦"""
    # è¨­ç½® API Key
    api_key = input("è«‹è¼¸å…¥æ‚¨çš„ OpenAI API Key: ")
    setup_environment(api_key)
    
    # è¼‰å…¥è³‡æ–™
    dataset_path = input("è«‹è¼¸å…¥è³‡æ–™é›†è·¯å¾‘: ")
    df = pd.read_csv(dataset_path)
    
    print(f"è¼‰å…¥è³‡æ–™ï¼š{len(df)} ç­†è¨˜éŒ„")
    
    # åˆå§‹åŒ–ç³»çµ±
    chunking_strategy = SmartChunkingStrategy(max_tokens=1024)
    
    # åŸ·è¡Œåˆ‡åˆ†
    all_chunks, stats = process_all_records(df, chunking_strategy)
    print(f"åˆ‡åˆ†å®Œæˆï¼š{stats['total_chunks']} å€‹ chunks")
    
    # åˆå§‹åŒ– Chroma
    chroma_arch = ChromaMixedArchitectureFixed()
    if chroma_arch.initialize_chroma_client():
        if chroma_arch.create_collections():
            collection_chunks = chroma_arch.prepare_chunks_for_collections(all_chunks)
            if chroma_arch.add_chunks_to_collections(collection_chunks):
                print("âœ… Chroma æ•¸æ“šåº«åˆå§‹åŒ–å®Œæˆ")
            else:
                print("âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—")
                return
        else:
            print("âŒ Collection å‰µå»ºå¤±æ•—")
            return
    else:
        print("âŒ Chroma å®¢æˆ¶ç«¯åˆå§‹åŒ–å¤±æ•—")
        return
    
    # åˆå§‹åŒ–æª¢ç´¢ç³»çµ±
    hybrid_search = HybridSearchStrategy(chroma_arch)
    rag_system = PromptGeneratorRAGSystem()
    
    print("ğŸ‰ ç³»çµ±åˆå§‹åŒ–å®Œæˆï¼")
    
    # æ¸¬è©¦æŸ¥è©¢
    while True:
        user_input = input("\nè«‹è¼¸å…¥æŸ¥è©¢ (è¼¸å…¥ 'quit' é€€å‡º): ")
        if user_input.lower() == 'quit':
            break
        
        context = input("è«‹è¼¸å…¥ä¸Šä¸‹æ–‡ (å¯é¸ï¼Œç›´æ¥æŒ‰ Enter è·³é): ")
        context = context if context.strip() else None
        
        result = rag_system.query(user_input, context)
        
        if "error" in result:
            print(f"âŒ æŸ¥è©¢å¤±æ•—ï¼š{result['error']}")
        else:
            print(f"âœ… æŸ¥è©¢æˆåŠŸï¼Œå ´æ™¯ï¼š{result['scenario']}")
            # é¡¯ç¤ºçµæœæ‘˜è¦...

if __name__ == "__main__":
    main()
